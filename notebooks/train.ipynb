{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc257ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from IPython.display import display, SVG, clear_output\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import chess\n",
    "import torch\n",
    "import time\n",
    "from src.leela_data import Lc0Loader, Lc0TeacherDataset\n",
    "from src.util import save_gif\n",
    "from src.train import train\n",
    "from src.leela_cnn import LeelaCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7a39b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory for game data chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files scanned: 1 files [00:00, 2526.69 files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 matching files.\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing worker processes: 100%|██████████| 1/1 [00:00<00:00, 110.17it/s]\n",
      "Filling shuffle buffer: 100%|██████████| 128/128 [00:07<00:00, 16.59it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 18 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "chunk_dir = '../data/small'\n",
    "files = list(Path(chunk_dir).glob(\"*.gz\"))\n",
    "dataset = Lc0TeacherDataset(\n",
    "    lc0_loader=Lc0Loader(chunk_dir=Path(chunk_dir))\n",
    ")\n",
    "board, mask, policy, value = next(iter(dataset))\n",
    "fig, axes = plt.subplots(3, 6, figsize=(14, 8))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(\n",
    "        board[i].numpy(),\n",
    "        # cmap='gray',\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6696c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.policy_loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "        self.value_loss_fn = torch.nn.L1Loss(reduction='mean')\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        mask: torch.Tensor,\n",
    "        policy_pred: torch.Tensor,\n",
    "        value_pred: torch.Tensor,\n",
    "        policy_target: torch.Tensor,\n",
    "        value_target: torch.Tensor,\n",
    "    ):\n",
    "        zeros = torch.zeros((policy_pred.shape)).to(mask.device)\n",
    "        policy_pred = torch.where(mask, policy_pred, zeros)\n",
    "        policy_target = torch.where(mask, policy_target, zeros)\n",
    "        policy_loss = self.policy_loss_fn(policy_pred, policy_target)\n",
    "        value_loss = self.value_loss_fn(value_pred.squeeze(), value_target.squeeze())\n",
    "        total_loss = policy_loss + value_loss\n",
    "        return total_loss, policy_loss, value_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c902b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29e01d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory for game data chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files scanned: 1 files [00:00, 2173.21 files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 matching files.\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing worker processes: 100%|██████████| 1/1 [00:00<00:00, 27.12it/s]\n",
      "Filling shuffle buffer:  34%|███▎      | 43/128 [00:02<00:04, 19.74it/s]Process SpawnProcess-8:\n",
      "Filling shuffle buffer:  34%|███▎      | 43/128 [00:02<00:05, 16.96it/s]Process SpawnProcess-5:\n",
      "\n",
      "Process SpawnProcess-2:\n",
      "Process SpawnProcess-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.14/3.14.0/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/process.py\", line 320, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.14/3.14.0/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/ml/chesshacks-training/notebooks/../src/new_data_pipeline.py\", line 208, in data_worker\n",
      "    current_file = next(file_gen)\n",
      "  File \"/Users/max/ml/chesshacks-training/notebooks/../src/new_data_pipeline.py\", line 26, in file_generator\n",
      "    yield deflate.gzip_decompress(file.read_bytes())\n",
      "          ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.14/3.14.0/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/process.py\", line 320, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.14/3.14.0/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/ml/chesshacks-training/notebooks/../src/new_data_pipeline.py\", line 197, in data_worker\n",
      "    main_process_access_event.wait()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.14/3.14.0/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/synchronize.py\", line 358, in wait\n",
      "    self._cond.wait(timeout)\n",
      "    ~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.14/3.14.0/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/synchronize.py\", line 270, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.14/3.14.0/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/process.py\", line 320, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.14/3.14.0/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/ml/chesshacks-training/notebooks/../src/new_data_pipeline.py\", line 197, in data_worker\n",
      "    main_process_access_event.wait()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.14/3.14.0/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/synchronize.py\", line 358, in wait\n",
      "    self._cond.wait(timeout)\n",
      "    ~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.14/3.14.0/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/synchronize.py\", line 270, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.14/3.14.0/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/process.py\", line 320, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.14/3.14.0/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max/ml/chesshacks-training/notebooks/../src/new_data_pipeline.py\", line 197, in data_worker\n",
      "    main_process_access_event.wait()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.14/3.14.0/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/synchronize.py\", line 358, in wait\n",
      "    self._cond.wait(timeout)\n",
      "    ~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.14/3.14.0/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/synchronize.py\", line 270, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m optim = torch.optim.Adam(model.parameters(), lr=\u001b[32m3e-4\u001b[39m)\n\u001b[32m      6\u001b[39m scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=\u001b[32m0.9\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mLeelaCNN v0.1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/chesshacks-training/notebooks/../src/train.py:197\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model_name, model, loss_fn, optimizer, scheduler, epochs, batch_size, train_set, val_set, num_workers, seed)\u001b[39m\n\u001b[32m    194\u001b[39m step = [\u001b[32m1\u001b[39m]\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs + \u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     train_loss, train_policy_loss, train_value_loss = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m     val_loss, val_policy_loss, val_value_loss = evaluate(model, device, val_loader, loss_fn)\n\u001b[32m    201\u001b[39m     scheduler.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/chesshacks-training/notebooks/../src/train.py:59\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, device, loader, loss_fn, optimizer, epoch, step, model_dir)\u001b[39m\n\u001b[32m     57\u001b[39m running_value_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m     58\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb_value\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb_value\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb_policy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb_value\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/chesshacks-training/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/chesshacks-training/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/chesshacks-training/.venv/lib/python3.14/site-packages/torch/utils/data/_utils/fetch.py:33\u001b[39m, in \u001b[36m_IterableDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m         data.append(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     35\u001b[39m         \u001b[38;5;28mself\u001b[39m.ended = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/chesshacks-training/notebooks/../src/leela_data.py:140\u001b[39m, in \u001b[36m__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lc0_loader: Lc0Loader):\n\u001b[32m    138\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen = lc0_loader\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m dp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gen:\n\u001b[32m    142\u001b[39m         board, policy, value = dp.board, dp.policy, dp.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/chesshacks-training/notebooks/../src/leela_data.py:4\u001b[39m, in \u001b[36m__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchess\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IterableDataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml/chesshacks-training/notebooks/../src/new_data_pipeline.py:288\u001b[39m, in \u001b[36mmultiprocess_generator\u001b[39m\u001b[34m(chunk_dir, batch_size, num_workers, skip_factor, shuffle_buffer_size, validation)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m trange(shuffle_buffer_size // batch_size, desc=\u001b[33m\"\u001b[39m\u001b[33mFilling shuffle buffer\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    287\u001b[39m     proc = i % num_workers\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     is_ready = \u001b[43marray_ready_events\u001b[49m\u001b[43m[\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSHUFFLE_EVENT_TIMEOUT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_ready:\n\u001b[32m    290\u001b[39m         proc_alive = processes[proc].is_alive()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.14/3.14.0/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/synchronize.py:358\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    356\u001b[39m     \u001b[38;5;28mself\u001b[39m._flag.release()\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._flag.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    361\u001b[39m     \u001b[38;5;28mself\u001b[39m._flag.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.14/3.14.0/Frameworks/Python.framework/Versions/3.14/lib/python3.14/multiprocessing/synchronize.py:270\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    266\u001b[39m     \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    269\u001b[39m     \u001b[38;5;66;03m# wait for notification or timeout\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_semaphore\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    272\u001b[39m     \u001b[38;5;66;03m# indicate that this thread has woken\u001b[39;00m\n\u001b[32m    273\u001b[39m     \u001b[38;5;28mself\u001b[39m._woken_count.release()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = LeelaCNN(\n",
    "    block_count=10,\n",
    "    filter_count=128,\n",
    ")\n",
    "optim = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.9)\n",
    "\n",
    "train(\n",
    "    model_name='LeelaCNN v0.1',\n",
    "    model=model,\n",
    "    loss_fn=Loss(),\n",
    "    optimizer=optim,\n",
    "    scheduler=scheduler,\n",
    "    train_set=dataset,\n",
    "    val_set=dataset,\n",
    "    batch_size=256,\n",
    "    num_workers=1,\n",
    "    epochs=10,\n",
    "    seed=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c112e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
